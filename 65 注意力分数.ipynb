{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[注意力分数](https://www.bilibili.com/video/BV1Tb4y167rb/?spm_id_from=333.788.recommend_more_video.0&vd_source=1d3a7b81d826789081d8b6870d4fff8e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"picture/截屏2022-06-21 14.24.03.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- α（x,xi）：注意力权重（权重一般是一组大于等于零，相加和为 1 的数）\n",
    "- 注意力分数：高斯核的指数部分（相当于是注意力权重归一化之前的版本）\n",
    "- 上图所展示的是：假设已知一些 key-value 对和一个 query，首先将 query 和每一个 key 通过注意力分数函数 a 和 softmax 运算得到注意力权重（与 key 对应的值的概率分布），将这些注意力权重再与已知的 value 进行加权求和，最终就得到了输出\n",
    "- 这张图里面的a为$-\\frac{1}{2}(x-x_i)^2 y_i$,但是显然a可以有多种写法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"picture/截屏2022-06-21 15.52.41.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此图也可以看出关键在于如何设计$a(q,k_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='picture/截屏2022-06-21 16.02.29.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 第一种设计思路:可加注意力层\n",
    "- 可学参数$W_k,W_q,v$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"picture/截屏2022-06-21 16.36.00.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 使用点积可以得到计算效率更高i的评分函数，但是点积操作要求 query 和 key 具有相同的长度\n",
    "- 假设 query 和 key 的所有元素都是独立的随机变量，并且都满足零均值和单位方差，那么两个向量的点积的均值为 0 ，方差为 d\n",
    "- 这里不需要学习任何东西，直接利用 $<q,k_i>$ 将 q 和 $k_i$ 做内积然后除以根号 d （除以根号 d 的目的是为了降低对 ki 的长度的敏感度，使得无论向量的长度如何，点积的方差在不考虑向量长度的情况下仍然是 1 ）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. 注意力分数是 query 和 key 的相似度（没有经过 normalize ），注意力权重是注意力分数的 softmax 结果（ 0 到 1 之间的数）\n",
    "2. 两种常见的注意力分数的计算\n",
    "- 有参数的版本：将 query 和 key 合并起来进入一个单隐藏层单输出的 MLP（在 query 和 key 向量长度不同的情况下）\n",
    "- 无参数的版本：直接将 query 和 key 做内积（在 query 和 key 向量长度一定的情况下），效率更高"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('d2l')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f7aa0bfac01ce1e861177f7ddac38fea2b037d61c5b30928011344cb8e12ea48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
