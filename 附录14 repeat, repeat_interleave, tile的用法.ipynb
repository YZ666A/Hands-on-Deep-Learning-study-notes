{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torch.repeat\n",
    "- 使张量沿着某个维度进行复制, 并且不仅可以复制张量，也可以拓展张量的维度:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 4]), torch.Size([4, 4]), torch.Size([2, 8]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.randn(2, 4)\n",
    "\n",
    "# 1. 沿着某个维度复制\n",
    "x.repeat(1, 1).size()  ,x.repeat(2, 1).size()  ,x.repeat(1, 2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 2, 4]), torch.Size([2, 2, 4]), torch.Size([1, 1, 2, 4]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. 不仅可以复制维度, 还可以拓展维度\n",
    "x.repeat(1, 1, 1).size()  ,x.repeat(2, 1, 1).size()  ,x.repeat(1, 1, 1, 1).size()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. repeat中传入的参数不可以少于x的维度\n",
    "# x.repeat(1)  # 报错"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.repeat_interleave\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.repeat_interleave的行为与numpy.repeat类似，但是和torch.repeat不同，这边还是以代码为例:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2580,  0.2197],\n",
       "        [-2.1634, -0.3043]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2580,  0.2197],\n",
       "        [-2.1634, -0.3043],\n",
       "        [-0.2580,  0.2197],\n",
       "        [-2.1634, -0.3043]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.repeat(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2580,  0.2197],\n",
       "        [-0.2580,  0.2197],\n",
       "        [-2.1634, -0.3043],\n",
       "        [-2.1634, -0.3043]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.repeat_interleave(2, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2580, -0.2580,  0.2197,  0.2197],\n",
       "        [-2.1634, -2.1634, -0.3043, -0.3043]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.repeat_interleave(2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2580, -0.2580,  0.2197,  0.2197, -2.1634, -2.1634, -0.3043, -0.3043])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 如果不传dim参数, 则默认复制后拉平\n",
    "x.repeat_interleave(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从这个代码可以看出来torch.repeat更像是把tensor作为一个整体进行复制, \n",
    "- 而torch.repeat_interleave更是针对tensor里的每个元素进行复制，\n",
    "- 并且torch.repeat_interleave可以通过传入一个一维的torch.Tensor来指定每个元素复制的次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [3, 4],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2], [3, 4]])\n",
    "torch.repeat_interleave(x, torch.tensor([1, 3]), dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.tile\n",
    "- torch.tile函数也是元素复制的一个函数, 但是在传参上和torch.repeat不同，但是也是以input为一个整体进行复制, torch.tile如果只传入一个参数的话, 默认是沿着行进行复制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1, 2], [3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 1, 2],\n",
       "         [3, 4, 3, 4]]),\n",
       " tensor([[1, 2, 1, 2],\n",
       "         [3, 4, 3, 4]]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.tile((2, )),x.repeat(1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.tile传入一个元组的话, 表示(行复制次数, 列复制次数)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 1, 2],\n",
       "        [3, 4, 3, 4],\n",
       "        [1, 2, 1, 2],\n",
       "        [3, 4, 3, 4]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2], [3, 4]])\n",
    "x.tile((2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当传入的参数少于需要复制的元素的维度时, 如果一个tensor的形状为(2, 2, 2)，传入tile中的参数为(2, 2)时, 会默认表示为(1, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4555,  1.7824],\n",
       "         [-0.7709, -0.0430]],\n",
       "\n",
       "        [[-0.1933, -1.1088],\n",
       "         [ 0.1955, -0.4354]]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 2, 2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4555,  1.7824,  0.4555,  1.7824],\n",
       "         [-0.7709, -0.0430, -0.7709, -0.0430],\n",
       "         [ 0.4555,  1.7824,  0.4555,  1.7824],\n",
       "         [-0.7709, -0.0430, -0.7709, -0.0430]],\n",
       "\n",
       "        [[-0.1933, -1.1088, -0.1933, -1.1088],\n",
       "         [ 0.1955, -0.4354,  0.1955, -0.4354],\n",
       "         [-0.1933, -1.1088, -0.1933, -1.1088],\n",
       "         [ 0.1955, -0.4354,  0.1955, -0.4354]]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.tile((2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用tile和reshape代替repeat_interleave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [1, 2, 3],\n",
       "        [1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [4, 5, 6],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]])  # shape: (2, 3)\n",
    "torch.repeat_interleave(x, repeats=3, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "直接使用tile, 无法得到类似的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 1, 2, 3, 1, 2, 3],\n",
       "        [4, 5, 6, 4, 5, 6, 4, 5, 6]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tile(x, (3,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tile(x, (3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [1, 2, 3],\n",
       "        [1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [4, 5, 6],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 需要使用 tile + reshape 才可以得到类似的结果\n",
    "torch.tile(x, (3, )).reshape(6,3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('d2l')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f7aa0bfac01ce1e861177f7ddac38fea2b037d61c5b30928011344cb8e12ea48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
