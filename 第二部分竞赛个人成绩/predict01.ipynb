{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用torch.utils.data.Dataset\n",
    "- 通过继承 torch.utils.data.Dataset 实现用户自定义读取数据集，需要实现__init__ __getitem__和__len__方法。\n",
    "    - 在__init__中，需要初始化文件路径或文件名列表，以方便后面在__getitem__中读取。在这里，返回了所有图片样本的路径self.all_image_paths以及对应的标签self.all_image_labels，并对mean和std值进行了reshape。\n",
    "    - 在__getitem__中，需要根据索引读取数据，并对数据进行预处理，返回数据对，例如（图片，标签）对。在这里，将一张图片调整为224×224尺寸并进行归一化，根据torch的输入图片通道要求(C,H,W)进行了转置，返回了(img, label)对。\n",
    "    - 在__len__中，需要返回整个数据集的数量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据处理\n",
    "import os\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "\n",
    "# Augmentation\n",
    "import albumentations\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import cv2\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from d2l import torch as d2l\n",
    "# 我们要做的第一件事就是拆分训练集与数据集\n",
    "# 标签含有字符串类型，需要通过preprocessing进行转换\n",
    "\n",
    "lr, num_epochs, batch_size = 1e-3, 50, 64\n",
    "seed = 666\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "root = './data/train.csv'\n",
    "def label_split(root):\n",
    "    root = pd.read_csv(root)\n",
    "    image = root['image'].tolist()\n",
    "    label = root['label'].to_list()\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    targets = le.fit_transform(label)\n",
    "    with open('./labels.pkl','wb') as file:\n",
    "        pickle.dump(dict(zip(targets,label)),file)\n",
    "    image_train,image_test, label_train, label_test =train_test_split(image,targets,test_size=0.1, random_state=seed)\n",
    "    return image_train,image_test, label_train, label_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = albumentations.Compose([\n",
    "            albumentations.Resize(320, 320), # 变换尺寸\n",
    "            albumentations.HorizontalFlip(p=0.5), # 水平翻转\n",
    "            albumentations.VerticalFlip(p=0.5), # 垂直翻转\n",
    "            albumentations.Rotate(limit=180, p=0.7), # 随机旋转\n",
    "            albumentations.RandomBrightnessContrast(), # 随机条件亮度和对比度\n",
    "            # 随机放射变换\n",
    "            albumentations.ShiftScaleRotate(\n",
    "                shift_limit=0.25, scale_limit=0.1, rotate_limit=0\n",
    "            ),\n",
    "            # 图像标准化\n",
    "            albumentations.Normalize(\n",
    "                [0.485, 0.456, 0.406], [0.229, 0.224, 0.225],\n",
    "                max_pixel_value=255.0, always_apply=True\n",
    "            ),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "transform_test = albumentations.Compose([\n",
    "            albumentations.Resize(320, 320),\n",
    "            albumentations.Normalize(\n",
    "                [0.485, 0.456, 0.406], [0.229, 0.224, 0.225],\n",
    "                max_pixel_value=255.0, always_apply=True\n",
    "            ),\n",
    "            ToTensorV2(p=1.0)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "class Mydataset(Dataset):\n",
    "    def __init__(self,image,label, transform):\n",
    "        \"\"\"\n",
    "        定义自己的数据集合\n",
    "        将图片转换为Tensor,归一化至[0,1]\n",
    "        transforms.Normalize(mean=[.5, .5, .5], std=[.5, .5, .5])  # 标准化至[-1,1]\n",
    "        imgs 因为所有图片的绝对路径，这里路径都储存在了train.csv中\n",
    "        所以这里路径应当根据csv来提供\n",
    "        \"\"\"\n",
    "        self.imgs = [os.path.join('./data',x) for x in image]\n",
    "        self.label=label\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_filepath = self.imgs[index]\n",
    "        image = cv2.imread(image_filepath)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image=image)[\"image\"]\n",
    "        label = torch.as_tensor(self.label[index])\n",
    "        return image,label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_train,image_test, label_train, label_test = label_split(root)\n",
    "train_iter = Mydataset(image_train,label_train,transform= transform_train)\n",
    "test_iter = Mydataset(image_test,label_test,transform= transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = DataLoader(train_iter,batch_size=batch_size,shuffle=False,num_workers=0)\n",
    "test_iter = DataLoader(test_iter,batch_size=batch_size,shuffle=False,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一步，定义残差块\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self,input_channels,num_channels,use_1x1conv=True, strides=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, num_channels,kernel_size=3, padding=1, stride=strides)\n",
    "        self.conv2 = nn.Conv2d(num_channels, num_channels,kernel_size=3, padding=1)\n",
    "        # 是否对输出使用1X1卷积层\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = nn.Conv2d(input_channels, num_channels,kernel_size=1, stride=strides)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        self.bn1 = nn.BatchNorm2d(num_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(num_channels)\n",
    "        self.relu = nn.ReLU(inplace=True) \n",
    "    \n",
    "    def forward(self,X):\n",
    "        Y = F.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3:\n",
    "            X = self.conv3(X)\n",
    "        # 这里是核心,输出残差\n",
    "        # 这里需要注意的是，设计Resnet，Y的shape需要和X保持一致\n",
    "        Y += X\n",
    "        return F.relu(Y)\n",
    "\n",
    "# ResNet模型\n",
    "# ResNet 的前两层跟之前介绍的GoogLeNet 中的⼀样：在输出通道数为64、步幅为2 的7X7 卷积层后，接\n",
    "# 步幅为2 的3X3 的最⼤汇聚层。不同之处在于ResNet 每个卷积层后增加了批量归⼀化层。\n",
    "b1 = nn.Sequential(\n",
    "    nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
    "    nn.BatchNorm2d(64), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "# 这种写法之前比较少见，通过数组的形式添加层，在直接*args添加进Sequential\n",
    "def resnet_block(input_channels, num_channels, num_residuals,first_block=False):\n",
    "    blk = []\n",
    "    for i in range(num_residuals):\n",
    "        if i == 0 and not first_block:\n",
    "            blk.append(Residual(input_channels, num_channels,use_1x1conv=True, strides=2))\n",
    "        else:\n",
    "            blk.append(Residual(num_channels, num_channels))\n",
    "    return blk\n",
    "\n",
    "b2 = nn.Sequential(*resnet_block(64, 64, 2, first_block=True))\n",
    "b3 = nn.Sequential(*resnet_block(64, 128, 2))\n",
    "b4 = nn.Sequential(*resnet_block(128, 256, 2))\n",
    "b5 = nn.Sequential(*resnet_block(256, 512, 2))\n",
    "net = nn.Sequential(\n",
    "    b1, \n",
    "    b2, \n",
    "    b3, \n",
    "    b4, \n",
    "    b5, \n",
    "    nn.AdaptiveAvgPool2d((1,1)),\n",
    "    nn.Flatten(), nn.Linear(512, 256))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape:\t torch.Size([1, 64, 56, 56])\n",
      "Sequential output shape:\t torch.Size([1, 64, 56, 56])\n",
      "Sequential output shape:\t torch.Size([1, 128, 28, 28])\n",
      "Sequential output shape:\t torch.Size([1, 256, 14, 14])\n",
      "Sequential output shape:\t torch.Size([1, 512, 7, 7])\n",
      "AdaptiveAvgPool2d output shape:\t torch.Size([1, 512, 1, 1])\n",
      "Flatten output shape:\t torch.Size([1, 512])\n",
      "Linear output shape:\t torch.Size([1, 256])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(size=(1, 3, 224, 224))\n",
    "for layer in net:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__,'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cuda:0\n"
     ]
    }
   ],
   "source": [
    "device =d2l.try_gpu()\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "net.apply(init_weights)\n",
    "print('training on', device)\n",
    "net.to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1轮精确度为7.51%\n",
      "第2轮精确度为17.79%\n",
      "第3轮精确度为28.97%\n",
      "第4轮精确度为39.50%\n",
      "第5轮精确度为52.65%\n",
      "第6轮精确度为56.50%\n",
      "第7轮精确度为63.45%\n",
      "第8轮精确度为67.53%\n",
      "第9轮精确度为68.85%\n",
      "第10轮精确度为73.24%\n",
      "第11轮精确度为74.74%\n",
      "第12轮精确度为74.96%\n",
      "第13轮精确度为79.05%\n",
      "第14轮精确度为79.15%\n",
      "第15轮精确度为79.90%\n",
      "第16轮精确度为80.77%\n",
      "第17轮精确度为80.58%\n",
      "第18轮精确度为81.58%\n",
      "第19轮精确度为70.09%\n",
      "第20轮精确度为83.62%\n",
      "第21轮精确度为83.95%\n",
      "第22轮精确度为83.86%\n",
      "第23轮精确度为85.08%\n",
      "第24轮精确度为86.26%\n",
      "第25轮精确度为85.34%\n",
      "第26轮精确度为84.77%\n",
      "第27轮精确度为88.17%\n",
      "第28轮精确度为86.82%\n",
      "第29轮精确度为87.17%\n",
      "第30轮精确度为87.74%\n",
      "第31轮精确度为87.87%\n",
      "第32轮精确度为87.63%\n",
      "第33轮精确度为88.12%\n",
      "第34轮精确度为89.32%\n",
      "第35轮精确度为87.93%\n",
      "第36轮精确度为88.94%\n",
      "第37轮精确度为89.03%\n",
      "第38轮精确度为88.38%\n",
      "第39轮精确度为89.02%\n",
      "第40轮精确度为89.75%\n",
      "第41轮精确度为90.16%\n",
      "第42轮精确度为89.45%\n",
      "第43轮精确度为89.19%\n",
      "第44轮精确度为90.49%\n",
      "第45轮精确度为89.21%\n",
      "第46轮精确度为90.13%\n",
      "第47轮精确度为90.77%\n",
      "第48轮精确度为90.07%\n",
      "第49轮精确度为90.51%\n",
      "第50轮精确度为91.34%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    for i, (X, y) in enumerate(train_iter):\n",
    "        optimizer.zero_grad()\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_hat = net(X)\n",
    "        l = loss(y_hat, y)\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "    s,i,acc = torch.tensor(0.0,device=device),0,torch.tensor(0.0,device=device)\n",
    "    for a, b in test_iter:\n",
    "        i +=1\n",
    "        a, b = a.to(device), b.to(device)\n",
    "        _, predicted = torch.max(net(a), 1)\n",
    "        acc += sum(predicted == b)/len(b)*100\n",
    "    print(f'第{epoch+1}轮精确度为{acc.tolist()/i:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'resnet.params')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('d2l')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f7aa0bfac01ce1e861177f7ddac38fea2b037d61c5b30928011344cb8e12ea48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
